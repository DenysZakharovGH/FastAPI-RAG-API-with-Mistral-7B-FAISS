# FastAPI RAG API with Mistralâ€‘7B & FAISS

A **productionâ€‘ready Retrievalâ€‘Augmented Generation (RAG) API** built with **FastAPI**, **FAISS**, and **Mistralâ€‘7Bâ€‘Instruct**. This project lets you query your own documents through an HTTP API while ensuring answers are grounded strictly in retrieved context.

> ğŸ¯ **Goal:** Provide fast, accurate, and sourceâ€‘aware answers from custom datasets with minimal hallucinations.

---

## ğŸš€ Key Features

- âš¡ **FastAPI** â€“ Highâ€‘performance, async REST API
- ğŸ§  **Mistralâ€‘7Bâ€‘Instruct** â€“ Openâ€‘weight LLM for generation
- ğŸ” **FAISS Vector Store** â€“ Fast similarity search at scale
- ğŸ§© **Retrievalâ€‘Augmented Generation (RAG)** â€“ Answers based only on retrieved context
- ğŸ“š **Source Attribution** â€“ Responses include supporting document chunks
- ğŸ³ **Docker & Docker Compose** â€“ Easy local and server deployment
- ğŸ”„ **Asyncâ€‘Safe Inference** â€“ Nonâ€‘blocking LLM execution
- ğŸ”§ **Configurable Pipeline** â€“ Chunking, embeddings, and model settings

---

## ğŸ—ï¸ Architecture Overview

```
User Query
   â†“
FastAPI Endpoint
   â†“
Embedding Model
   â†“
FAISS Similarity Search
   â†“
Relevant Context Chunks
   â†“
RAG Prompt Assembly
   â†“
Mistralâ€‘7Bâ€‘Instruct
   â†“
Answer + Sources
```

### How It Works

1. **Documents are ingested** and split into chunks
2. **Embeddings** are generated for each chunk
3. Chunks are stored in **FAISS** for fast retrieval
4. A user query is embedded and matched against FAISS
5. Topâ€‘K relevant chunks are injected into a **RAG prompt**
6. **Mistralâ€‘7B** generates an answer strictly from context
7. API returns the answer **with sources**

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ app/                # FastAPI application logic
â”‚   â”œâ”€â”€ api/            # API routes
â”‚   â”œâ”€â”€ core/           # Configuration & settings
â”‚   â”œâ”€â”€ rag/            # RAG pipeline (retrieval, prompts, generation)
â”‚   â””â”€â”€ models/         # Request/response schemas
â”œâ”€â”€ data_storage/       # FAISS indexes and persisted data
â”œâ”€â”€ docs/               # Additional documentation
â”œâ”€â”€ frontend/           # (Optional) UI for querying the API
â”œâ”€â”€ tests/              # Test suite
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

---

## ğŸ“¦ Installation

### Option 1: Docker (Recommended)

```bash
git clone https://github.com/DenysZakharovGH/FastAPI-RAG-API-with-Mistral-7B-FAISS.git
cd FastAPI-RAG-API-with-Mistral-7B-FAISS
docker-compose up --build
```

The API will be available at:
```
http://localhost:8000
```
---

[![Demo](docs/demo.gif)]

---

---

### Option 2: Local Setup

```bash
git clone https://github.com/DenysZakharovGH/FastAPI-RAG-API-with-Mistral-7B-FAISS.git
cd FastAPI-RAG-API-with-Mistral-7B-FAISS
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
uvicorn app.main:app --reload
```

---

## ğŸ”Œ API Usage

### Ask a Question

**Endpoint**
```
POST /ask
```

**Request Body**
```json
{
  "question": "What is the length of a giraffe's tongue?"
}
```

**Response**
```json
{
  "answer": "A giraffe's tongue typically measures between 18 and 20 inches in length.",
  "sources": [
    {
      "content": "Giraffe tongues can reach up to 20 inches...",
      "metadata": {
        "source": "animals.txt"
      }
    }
  ]
}
```

---

## ğŸ§  Hallucination Control

This project is designed to **minimize hallucinations**:

- The model is instructed to answer **only from provided context**
- If no relevant context is found, the model responds accordingly
- Prompt templates explicitly restrict speculative answers

---

## âš™ï¸ Configuration

Most settings can be configured via environment variables or config files:

- Embedding model
- Chunk size & overlap
- FAISS index type
- Number of retrieved chunks (Topâ€‘K)
- LLM generation parameters (temperature, max tokens)

---

## ğŸ§ª Testing

```bash
pytest
```

---

## ğŸ“ˆ Performance & Scaling Ideas

- GPU acceleration (FAISSâ€‘GPU, CUDAâ€‘enabled inference)
- Result caching (Redis)
- Streaming responses
- Multiâ€‘index or multiâ€‘tenant vector stores

---

## ğŸ” Production Notes

- Add authentication (JWT / API keys)
- Enable request rate limiting
- Monitor latency and memory usage
- Use persistent volumes for FAISS indexes

---

## ğŸ¤ Contributing

Contributions are welcome!

1. Fork the repo
2. Create a feature branch
3. Commit your changes
4. Open a pull request

---

## ğŸ“œ License

This project is licensed under the **MIT License**.

---

## ğŸ‘¤ Author

**Denys Zakharov**  
GitHub: https://github.com/DenysZakharovGH

---
